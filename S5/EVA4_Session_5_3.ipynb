{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA4 - Session 5-3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3RMqzYwsBYZ",
        "colab_type": "text"
      },
      "source": [
        "Target:\n",
        "\n",
        "    Max epochs = 15\n",
        "    Number of parameters < 10k\n",
        "    Adding GAP layer\n",
        "\n",
        "Result:\n",
        "\n",
        "    1st run:\n",
        "      Change: Added GAP layer with kernel size = 5\n",
        "      Parameters : 8,634\n",
        "      Train accuracy = 98.80%\n",
        "      Test accuracy = 98.55%\n",
        "\n",
        "    2nd run : \n",
        "      Change : GAP layer with kernel size = 7\n",
        "               Added extra convolution layer before GAP\n",
        "      Parameters : 8,634\n",
        "      Train accuracy = 98.54%\n",
        "      Test accuracy = 98.28%\n",
        "\n",
        "\n",
        "Analysis:\n",
        "\n",
        "    1st iteration - Changed the skeleton, removed 3 conv layers and added a GAP layer - Got max accuracy of 98.55%\n",
        "    2nd iteration - Added a conv layer before GAP, GAP layer with kernel size 7 - got accuracy of 98.28%\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Cx9q2QFgM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Original network with less parameters, so that training is also faster\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.drop1 = nn.Dropout(0.1)  \n",
        "        self.conv1 = nn.Conv2d(1, 16, 3, padding=0)         #input - 28 OUtput - 26 RF\n",
        "        self.conv2 = nn.Conv2d(16, 10, 3, padding=0)        #input - 26 OUtput - 24\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)                     #input - 24 OUtput - 12\n",
        "        self.bnm2d1 = nn.BatchNorm2d(10) \n",
        "        self.conv3 = nn.Conv2d(10, 10, 3, padding=0)        #input - 12 OUtput - 10\n",
        "        self.conv4 = nn.Conv2d(10, 16, 3, padding=0)        #input - 10 OUtput - 8\n",
        "        # self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.bnm2d2 = nn.BatchNorm2d(16) \n",
        "        self.conv5 = nn.Conv2d(16, 16, 3, padding=0)        #input - 8  OUtput - 6\n",
        "        self.conv6 = nn.Conv2d(16, 16, 3, padding=1)        #input - 6  OUtput - 6\n",
        "        # self.conv7 = nn.Conv2d(16, 16, 3, padding=1)      #input - 6  OUtput - 6\n",
        "        self.gap = nn.AvgPool2d(kernel_size=6)\n",
        "        self.conv8 = nn.Conv2d(16,10,1)                     \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bnm2d1(self.pool1(F.relu(self.drop1(self.conv2(F.relu(self.drop1(self.conv1(x))))))))\n",
        "        x = self.bnm2d2(F.relu(self.drop1(self.conv4(F.relu(self.drop1(self.conv3(x)))))))\n",
        "        x = self.conv6(F.relu(self.drop1(self.conv5(x))))\n",
        "        # x = self.conv7(x)\n",
        "        x = self.gap(x)\n",
        "        x = self.conv8(x)\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xdydjYTZFyi3",
        "outputId": "6e060dc7-91f2-4b2f-929e-9197854dc319",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "# !pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 26, 26]             160\n",
            "           Dropout-2           [-1, 16, 26, 26]               0\n",
            "            Conv2d-3           [-1, 10, 24, 24]           1,450\n",
            "           Dropout-4           [-1, 10, 24, 24]               0\n",
            "         MaxPool2d-5           [-1, 10, 12, 12]               0\n",
            "       BatchNorm2d-6           [-1, 10, 12, 12]              20\n",
            "            Conv2d-7           [-1, 10, 10, 10]             910\n",
            "           Dropout-8           [-1, 10, 10, 10]               0\n",
            "            Conv2d-9             [-1, 16, 8, 8]           1,456\n",
            "          Dropout-10             [-1, 16, 8, 8]               0\n",
            "      BatchNorm2d-11             [-1, 16, 8, 8]              32\n",
            "           Conv2d-12             [-1, 16, 6, 6]           2,320\n",
            "          Dropout-13             [-1, 16, 6, 6]               0\n",
            "           Conv2d-14             [-1, 16, 6, 6]           2,320\n",
            "        AvgPool2d-15             [-1, 16, 1, 1]               0\n",
            "           Conv2d-16             [-1, 10, 1, 1]             170\n",
            "================================================================\n",
            "Total params: 8,838\n",
            "Trainable params: 8,838\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.33\n",
            "Params size (MB): 0.03\n",
            "Estimated Total Size (MB): 0.36\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    correct = 0\n",
        "    processed = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred = model(data)\n",
        "\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = y_pred.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        processed += len(data)\n",
        "\n",
        "        # pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "        train_acc.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMWbLWO6FuHb",
        "colab_type": "code",
        "outputId": "158d77dd-09de-4576-d8b3-66ae10fe9163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# def __init__(self):\n",
        "#     super(Net, self).__init__()\n",
        "#     self.drop1 = nn.Dropout(0.1)  \n",
        "#     self.conv1 = nn.Conv2d(1, 16, 3, padding=1)     #input - 28 Output - 28 GRF - \n",
        "#     self.conv2 = nn.Conv2d(16, 16, 3, padding=1)    #input - 28 Output - 28 GRF - \n",
        "#     self.pool1 = nn.MaxPool2d(2, 2)                 #input - 28 Output - 14 GRF - \n",
        "#     self.bnm2d1 = nn.BatchNorm2d(16)                #input - 14 Output - 14 GRF - \n",
        "#     self.conv3 = nn.Conv2d(16, 16, 3, padding=1)    #input - 14 Output - 14 GRF - \n",
        "#     self.conv4 = nn.Conv2d(16, 16, 3, padding=1)    #input - 14 Output - 14 GRF - \n",
        "#     self.pool2 = nn.MaxPool2d(2, 2)                 #input - 14 Output - 7  GRF - \n",
        "#     self.bnm2d2 = nn.BatchNorm2d(16)                #input - 7  Output - 7  GRF - \n",
        "#     # self.conv5 = nn.Conv2d(16, 16, 3)\n",
        "#     # self.conv6 = nn.Conv2d(16, 10, 3)\n",
        "#     self.conv7 = nn.Conv2d(16, 10, 3)\n",
        "#     self.gap = nn.AvgPool2d(kernel_size=5)\n",
        "\n",
        "# def forward(self, x):\n",
        "#     x = self.pool1(self.drop1(F.relu(self.bnm2d1(self.conv2(self.drop1(F.relu(self.bnm2d1(self.conv1(x)))))))))\n",
        "#     x = self.pool2(self.drop1(F.relu(self.bnm2d2(self.conv4(self.drop1(F.relu(self.bnm2d1(self.conv3(x)))))))))\n",
        "#     # x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
        "#     # x = self.conv6(F.relu(self.conv5(x)))\n",
        "#     x = self.conv7(x)\n",
        "#     x = self.gap(x) \n",
        "\n",
        "#     x = x.view(-1, 10)\n",
        "#     return F.log_softmax(x)\n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(1, 15):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "loss=0.09281978756189346 batch_id=468 Accuracy=85.89: 100%|██████████| 469/469 [00:12<00:00, 38.07it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.1459, Accuracy: 6023/10000 (60.23%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.1645670086145401 batch_id=468 Accuracy=96.81: 100%|██████████| 469/469 [00:12<00:00, 38.38it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.0231, Accuracy: 6707/10000 (67.07%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.10403452068567276 batch_id=468 Accuracy=97.58: 100%|██████████| 469/469 [00:12<00:00, 38.05it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.1722, Accuracy: 6625/10000 (66.25%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.11307525634765625 batch_id=468 Accuracy=97.94: 100%|██████████| 469/469 [00:12<00:00, 37.96it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.8477, Accuracy: 7227/10000 (72.27%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.049388185143470764 batch_id=468 Accuracy=98.17: 100%|██████████| 469/469 [00:12<00:00, 37.48it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.1483, Accuracy: 6642/10000 (66.42%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.04771122708916664 batch_id=468 Accuracy=98.27: 100%|██████████| 469/469 [00:12<00:00, 37.56it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.0641, Accuracy: 6873/10000 (68.73%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.09227174520492554 batch_id=468 Accuracy=98.43: 100%|██████████| 469/469 [00:12<00:00, 37.42it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.2370, Accuracy: 6071/10000 (60.71%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.019674649462103844 batch_id=468 Accuracy=98.50: 100%|██████████| 469/469 [00:12<00:00, 37.77it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.0899, Accuracy: 6860/10000 (68.60%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.0411565862596035 batch_id=468 Accuracy=98.50: 100%|██████████| 469/469 [00:11<00:00, 39.42it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.2765, Accuracy: 6011/10000 (60.11%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.0580802857875824 batch_id=468 Accuracy=98.60: 100%|██████████| 469/469 [00:12<00:00, 38.89it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.7107, Accuracy: 7609/10000 (76.09%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.01041578222066164 batch_id=468 Accuracy=98.71: 100%|██████████| 469/469 [00:11<00:00, 39.42it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.8438, Accuracy: 7389/10000 (73.89%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.056161731481552124 batch_id=468 Accuracy=98.73: 100%|██████████| 469/469 [00:11<00:00, 39.60it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.6488, Accuracy: 7695/10000 (76.95%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.13909229636192322 batch_id=468 Accuracy=98.78: 100%|██████████| 469/469 [00:11<00:00, 39.77it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.5535, Accuracy: 8021/10000 (80.21%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.006018439773470163 batch_id=468 Accuracy=98.75: 100%|██████████| 469/469 [00:11<00:00, 39.34it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.6484, Accuracy: 7743/10000 (77.43%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbmWqLPD6JYk",
        "colab_type": "code",
        "outputId": "3fd0fa9b-8e58-4bee-93b0-fa0138a22d82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# def __init__(self):\n",
        "#     super(Net, self).__init__()\n",
        "#     self.drop1 = nn.Dropout(0.1)  \n",
        "#     self.conv1 = nn.Conv2d(1, 16, 3, padding=1) #input -? OUtput? RF\n",
        "#     self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "#     self.pool1 = nn.MaxPool2d(2, 2)\n",
        "#     self.bnm2d1 = nn.BatchNorm2d(32) \n",
        "#     self.conv3 = nn.Conv2d(32, 16, 3, padding=1)\n",
        "#     self.conv4 = nn.Conv2d(16, 16, 3, padding=1)\n",
        "#     self.pool2 = nn.MaxPool2d(2, 2)\n",
        "#     self.bnm2d2 = nn.BatchNorm2d(16) \n",
        "#     # self.conv5 = nn.Conv2d(16, 10, 3)\n",
        "#     # self.conv6 = nn.Conv2d(16, 16, 3)\n",
        "#     self.conv7 = nn.Conv2d(16, 10, 3)\n",
        "#     self.gap = nn.AvgPool2d(kernel_size=5)\n",
        "\n",
        "# def forward(self, x):\n",
        "#     x = self.bnm2d1(self.pool1(F.relu(self.drop1(self.conv2(F.relu(self.drop1(self.conv1(x))))))))\n",
        "#     x = self.bnm2d2(self.pool2(F.relu(self.drop1(self.conv4(F.relu(self.drop1(self.conv3(x))))))))\n",
        "#     # x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
        "#     x = self.conv7(x)\n",
        "#     x = self.gap(x)\n",
        "#     x = x.view(-1, 10)\n",
        "#     return F.log_softmax(x)\n",
        "\n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(1, 15):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "loss=0.058040838688611984 batch_id=468 Accuracy=87.36: 100%|██████████| 469/469 [00:12<00:00, 39.05it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1526, Accuracy: 9578/10000 (95.78%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.19096799194812775 batch_id=468 Accuracy=96.93: 100%|██████████| 469/469 [00:11<00:00, 39.41it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1057, Accuracy: 9704/10000 (97.04%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.10852020978927612 batch_id=468 Accuracy=97.59: 100%|██████████| 469/469 [00:11<00:00, 39.39it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0848, Accuracy: 9762/10000 (97.62%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.09089091420173645 batch_id=468 Accuracy=98.06: 100%|██████████| 469/469 [00:11<00:00, 40.16it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0789, Accuracy: 9793/10000 (97.93%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.1171332597732544 batch_id=468 Accuracy=98.21: 100%|██████████| 469/469 [00:11<00:00, 39.69it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0725, Accuracy: 9793/10000 (97.93%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.033811673521995544 batch_id=468 Accuracy=98.38: 100%|██████████| 469/469 [00:11<00:00, 40.06it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0560, Accuracy: 9850/10000 (98.50%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.05723206326365471 batch_id=468 Accuracy=98.47: 100%|██████████| 469/469 [00:11<00:00, 39.92it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0818, Accuracy: 9773/10000 (97.73%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.017972305417060852 batch_id=468 Accuracy=98.59: 100%|██████████| 469/469 [00:11<00:00, 39.64it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0483, Accuracy: 9862/10000 (98.62%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.033598072826862335 batch_id=468 Accuracy=98.66: 100%|██████████| 469/469 [00:11<00:00, 40.22it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0653, Accuracy: 9792/10000 (97.92%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.0656542107462883 batch_id=468 Accuracy=98.72: 100%|██████████| 469/469 [00:11<00:00, 39.99it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0520, Accuracy: 9832/10000 (98.32%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.005115717649459839 batch_id=468 Accuracy=98.77: 100%|██████████| 469/469 [00:11<00:00, 40.23it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0583, Accuracy: 9835/10000 (98.35%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.02643761783838272 batch_id=468 Accuracy=98.72: 100%|██████████| 469/469 [00:11<00:00, 41.16it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0424, Accuracy: 9867/10000 (98.67%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.05140615627169609 batch_id=468 Accuracy=98.80: 100%|██████████| 469/469 [00:11<00:00, 40.64it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0492, Accuracy: 9848/10000 (98.48%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.014406204223632812 batch_id=468 Accuracy=98.80: 100%|██████████| 469/469 [00:11<00:00, 41.08it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0502, Accuracy: 9855/10000 (98.55%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0qtfkSuGZpM",
        "colab_type": "code",
        "outputId": "2a943a8b-906e-4b25-90fa-b2a824e49551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# def __init__(self):\n",
        "#     super(Net, self).__init__()\n",
        "#     self.drop1 = nn.Dropout(0.1)  \n",
        "#     self.conv1 = nn.Conv2d(1, 16, 3, padding=1) #input -? OUtput? RF\n",
        "#     self.conv2 = nn.Conv2d(16, 16, 3, padding=1)\n",
        "#     self.pool1 = nn.MaxPool2d(2, 2)\n",
        "#     self.bnm2d1 = nn.BatchNorm2d(16) \n",
        "#     self.conv3 = nn.Conv2d(16, 16, 3, padding=1)\n",
        "#     self.conv4 = nn.Conv2d(16, 16, 3, padding=1)\n",
        "#     self.pool2 = nn.MaxPool2d(2, 2)\n",
        "#     self.bnm2d2 = nn.BatchNorm2d(16) \n",
        "#     # self.conv5 = nn.Conv2d(16, 16, 3, padding=1)\n",
        "#     # self.conv6 = nn.Conv2d(16, 16, 3, padding=1)\n",
        "#     self.conv7 = nn.Conv2d(16, 10, 3, padding=1)\n",
        "#     self.gap = nn.AvgPool2d(kernel_size=7)\n",
        "\n",
        "# def forward(self, x):\n",
        "#     x = self.bnm2d1(self.pool1(F.relu(self.drop1(self.conv2(F.relu(self.drop1(self.conv1(x))))))))\n",
        "#     x = self.bnm2d2(self.pool2(F.relu(self.drop1(self.conv4(F.relu(self.drop1(self.conv3(x))))))))\n",
        "#     # x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
        "#     x = self.conv7(x)\n",
        "#     x = self.gap(x)\n",
        "#     x = x.view(-1, 10)\n",
        "#     return F.log_softmax(x)\n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(1, 15):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "loss=0.12798148393630981 batch_id=468 Accuracy=82.24: 100%|██████████| 469/469 [00:12<00:00, 37.91it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.2285, Accuracy: 9399/10000 (93.99%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.2033967226743698 batch_id=468 Accuracy=96.31: 100%|██████████| 469/469 [00:11<00:00, 39.20it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1459, Accuracy: 9580/10000 (95.80%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.14860843122005463 batch_id=468 Accuracy=97.14: 100%|██████████| 469/469 [00:11<00:00, 39.67it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1132, Accuracy: 9686/10000 (96.86%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.14144526422023773 batch_id=468 Accuracy=97.69: 100%|██████████| 469/469 [00:11<00:00, 40.48it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1058, Accuracy: 9692/10000 (96.92%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.09398609399795532 batch_id=468 Accuracy=97.83: 100%|██████████| 469/469 [00:11<00:00, 40.25it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0909, Accuracy: 9747/10000 (97.47%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.08231160789728165 batch_id=468 Accuracy=97.94: 100%|██████████| 469/469 [00:11<00:00, 39.76it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0901, Accuracy: 9739/10000 (97.39%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.03567470982670784 batch_id=468 Accuracy=98.16: 100%|██████████| 469/469 [00:11<00:00, 39.54it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0782, Accuracy: 9766/10000 (97.66%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.012962947599589825 batch_id=468 Accuracy=98.25: 100%|██████████| 469/469 [00:11<00:00, 39.68it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0710, Accuracy: 9793/10000 (97.93%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.028720630332827568 batch_id=468 Accuracy=98.33: 100%|██████████| 469/469 [00:11<00:00, 39.09it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0830, Accuracy: 9758/10000 (97.58%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.07522069662809372 batch_id=468 Accuracy=98.41: 100%|██████████| 469/469 [00:12<00:00, 38.98it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0688, Accuracy: 9800/10000 (98.00%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.020643100142478943 batch_id=468 Accuracy=98.42: 100%|██████████| 469/469 [00:12<00:00, 38.73it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0636, Accuracy: 9799/10000 (97.99%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.020270755514502525 batch_id=468 Accuracy=98.48: 100%|██████████| 469/469 [00:11<00:00, 39.14it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0783, Accuracy: 9758/10000 (97.58%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.0911831185221672 batch_id=468 Accuracy=98.54: 100%|██████████| 469/469 [00:11<00:00, 39.64it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0594, Accuracy: 9828/10000 (98.28%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.014485458843410015 batch_id=468 Accuracy=98.51: 100%|██████████| 469/469 [00:11<00:00, 39.19it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0681, Accuracy: 9798/10000 (97.98%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShikK4HXXID4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}